{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PDF Translator - Google Colab\n",
        "\n",
        "**Translate scientific PDFs with local LLMs (Ollama) or OpenAI**\n",
        "\n",
        "© 2025 Sven Kalinowski with small help of Lino Casu\n",
        "Licensed under the Anti-Capitalist Software License v1.4\n",
        "\n",
        "---\n",
        "\n",
        "## Two Options:\n",
        "\n",
        "### Option A: Ollama (FREE, runs locally on Colab GPU)\n",
        "- No API key needed\n",
        "- Runs entirely on Google's servers\n",
        "- Your data stays in your Colab session\n",
        "- Requires GPU runtime (T4 is free)\n",
        "\n",
        "### Option B: OpenAI API (paid, better quality)\n",
        "- Requires OpenAI API key\n",
        "- Better translation quality (GPT-4)\n",
        "- Your data is sent to OpenAI servers\n",
        "\n",
        "---\n",
        "\n",
        "## Security Information\n",
        "\n",
        "### Ollama (Option A):\n",
        "- **100% local** - runs on Google Colab's GPU\n",
        "- No data leaves the Colab VM\n",
        "- Session is deleted when you close Colab\n",
        "\n",
        "### OpenAI API (Option B):\n",
        "- API key is stored **only in your Colab session**\n",
        "- Key is stored in `userdata` (Google Colab Secrets)\n",
        "- **Never shared** with notebook author or others\n",
        "- Key is deleted when session ends\n",
        "- Your PDFs are sent to OpenAI for processing\n",
        "\n",
        "---\n",
        "\n",
        "## GPU Runtime Setup\n",
        "\n",
        "1. Click **Runtime** → **Change runtime type**\n",
        "2. Select **T4 GPU** (free) or **A100** (Colab Pro)\n",
        "3. Click **Save**\n",
        "\n",
        "| GPU | VRAM | Recommended Model | ~Pages |\n",
        "|-----|------|-------------------|--------|\n",
        "| T4 | 16 GB | `llama3.1:8b` | ~32 |\n",
        "| A100 | 40 GB | `mixtral:8x7b` | ~80 |\n",
        "| L4 | 24 GB | `qwen2.5:14b` | ~65 |"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1. Check GPU\n",
        "!nvidia-smi --query-gpu=name,memory.total --format=csv\n",
        "import torch\n",
        "print(f\"\\nCUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    vram_gb = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
        "    print(f\"VRAM: {vram_gb:.1f} GB\")\n",
        "    if vram_gb >= 16:\n",
        "        print(\"\\nRecommended: llama3.1:8b or qwen2.5:7b\")\n",
        "    elif vram_gb >= 24:\n",
        "        print(\"\\nRecommended: qwen2.5:14b or mistral-nemo:12b\")\n",
        "else:\n",
        "    print(\"\\nNo GPU! Please enable GPU runtime.\")"
      ],
      "metadata": {
        "id": "check_gpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Option A: Ollama (FREE, Local)\n",
        "Run the following cells to use Ollama (no API key needed)"
      ],
      "metadata": {
        "id": "ollama_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2A. Install Ollama\n",
        "!curl -fsSL https://ollama.ai/install.sh | sh\n",
        "print(\"\\nOllama installed!\")"
      ],
      "metadata": {
        "id": "install_ollama"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3A. Start Ollama Server\n",
        "import subprocess\n",
        "import time\n",
        "import requests\n",
        "\n",
        "subprocess.Popen([\"ollama\", \"serve\"], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "print(\"Waiting for Ollama server...\")\n",
        "time.sleep(5)\n",
        "\n",
        "try:\n",
        "    r = requests.get(\"http://localhost:11434/api/tags\", timeout=5)\n",
        "    if r.status_code == 200:\n",
        "        print(\"Ollama server running!\")\n",
        "except:\n",
        "    print(\"Ollama server not reachable. Please run this cell again.\")"
      ],
      "metadata": {
        "id": "start_ollama"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 4A. Download Model\n",
        "model = \"llama3.1:8b\" #@param [\"llama3.1:8b\", \"qwen2.5:7b\", \"qwen2.5:14b\", \"mistral:7b\", \"mistral-nemo:12b\"]\n",
        "\n",
        "print(f\"Downloading {model} (may take a few minutes)...\")\n",
        "!ollama pull {model}\n",
        "print(f\"\\nModel {model} ready!\")"
      ],
      "metadata": {
        "id": "download_model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Option B: OpenAI API (Better Quality, Paid)\n",
        "\n",
        "## API Key Security\n",
        "\n",
        "Your OpenAI API key is stored securely:\n",
        "- Stored in **Google Colab Secrets** (your Google account only)\n",
        "- **Never visible** to notebook author or other users\n",
        "- **Automatically deleted** when session ends\n",
        "- Only used for API calls during your session\n",
        "\n",
        "### How to add your API key:\n",
        "1. Click the **key icon** in the left sidebar\n",
        "2. Add a new secret named `OPENAI_API_KEY`\n",
        "3. Paste your API key as the value\n",
        "4. Enable notebook access"
      ],
      "metadata": {
        "id": "openai_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2B. Setup OpenAI (Optional)\n",
        "!pip install -q openai\n",
        "\n",
        "# Try to get API key from Colab Secrets\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "    if OPENAI_API_KEY:\n",
        "        print(\"OpenAI API key loaded from Colab Secrets!\")\n",
        "        print(\"Your key is secure and only visible to you.\")\n",
        "    else:\n",
        "        print(\"No API key found. Add it to Colab Secrets (key icon in sidebar).\")\n",
        "except:\n",
        "    print(\"Colab Secrets not available. You can enter key manually below.\")\n",
        "    OPENAI_API_KEY = None"
      ],
      "metadata": {
        "id": "setup_openai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 5. Install Dependencies\n",
        "!pip install -q PyPDF2 pdfplumber langdetect requests\n",
        "print(\"Dependencies installed!\")"
      ],
      "metadata": {
        "id": "install_deps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 6. PDF Translator Code\n",
        "import requests\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Tuple, Optional\n",
        "\n",
        "@dataclass\n",
        "class Block:\n",
        "    page: int\n",
        "    content: str\n",
        "    translated: str = \"\"\n",
        "\n",
        "OLLAMA_URL = \"http://localhost:11434\"\n",
        "\n",
        "def extract_pdf(pdf_path: str) -> Tuple[List[Block], str]:\n",
        "    import pdfplumber\n",
        "    from langdetect import detect\n",
        "    blocks = []\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for i, page in enumerate(pdf.pages):\n",
        "            text = page.extract_text(layout=True) or \"\"\n",
        "            for para in text.split(\"\\n\\n\"):\n",
        "                para = para.strip()\n",
        "                if para:\n",
        "                    blocks.append(Block(page=i+1, content=para))\n",
        "    sample = \" \".join(b.content for b in blocks[:3])\n",
        "    lang = detect(sample) if sample else \"en\"\n",
        "    return blocks, lang\n",
        "\n",
        "def translate_ollama(text: str, model: str, source: str, target: str) -> str:\n",
        "    if not text.strip():\n",
        "        return text\n",
        "    system = f\"\"\"You are a professional scientific translator.\n",
        "You MUST translate ALL text to {target} ONLY.\n",
        "NEVER use any other language than {target}.\n",
        "Keep all mathematical formulas unchanged.\n",
        "Output ONLY the translation.\"\"\"\n",
        "    user = f\"Translate from {source} to {target}. Keep formulas unchanged.\\n\\nText:\\n{text}\"\n",
        "    try:\n",
        "        r = requests.post(f\"{OLLAMA_URL}/api/chat\", json={\n",
        "            \"model\": model,\n",
        "            \"messages\": [{\"role\": \"system\", \"content\": system}, {\"role\": \"user\", \"content\": user}],\n",
        "            \"stream\": False,\n",
        "            \"options\": {\"temperature\": 0.1, \"num_predict\": 8192}\n",
        "        }, timeout=300)\n",
        "        if r.status_code == 200:\n",
        "            return r.json().get(\"message\", {}).get(\"content\", text)\n",
        "    except Exception as e:\n",
        "        print(f\"Ollama error: {e}\")\n",
        "    return text\n",
        "\n",
        "def translate_openai(text: str, api_key: str, source: str, target: str) -> str:\n",
        "    if not text.strip() or not api_key:\n",
        "        return text\n",
        "    from openai import OpenAI\n",
        "    client = OpenAI(api_key=api_key)\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": f\"Translate to {target}. Keep formulas unchanged. Output only translation.\"},\n",
        "                {\"role\": \"user\", \"content\": text}\n",
        "            ],\n",
        "            temperature=0.1\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        print(f\"OpenAI error: {e}\")\n",
        "    return text\n",
        "\n",
        "def translate_pdf(pdf_path: str, target: str, backend: str = \"ollama\", model: str = \"llama3.1:8b\", api_key: str = None) -> str:\n",
        "    print(f\"Extracting: {pdf_path}\")\n",
        "    blocks, source = extract_pdf(pdf_path)\n",
        "    print(f\"{len(blocks)} blocks, language: {source}\")\n",
        "    print(f\"Translating to {target} with {backend}...\")\n",
        "    for i, b in enumerate(blocks):\n",
        "        print(f\"  Block {i+1}/{len(blocks)}\", end=\"\\r\")\n",
        "        if backend == \"openai\" and api_key:\n",
        "            b.translated = translate_openai(b.content, api_key, source, target)\n",
        "        else:\n",
        "            b.translated = translate_ollama(b.content, model, source, target)\n",
        "    print(\"\\nDone!\")\n",
        "    return \"\\n\\n\".join(b.translated for b in blocks)\n",
        "\n",
        "print(\"PDF Translator ready!\")"
      ],
      "metadata": {
        "id": "translator_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 7. Upload and Translate PDF\n",
        "from google.colab import files\n",
        "\n",
        "#@markdown ### Settings\n",
        "target_language = \"German\" #@param [\"German\", \"English\", \"French\", \"Spanish\", \"Italian\", \"Japanese\", \"Chinese\"]\n",
        "backend = \"ollama\" #@param [\"ollama\", \"openai\"]\n",
        "ollama_model = \"llama3.1:8b\" #@param [\"llama3.1:8b\", \"qwen2.5:7b\", \"qwen2.5:14b\", \"mistral:7b\"]\n",
        "\n",
        "# Get OpenAI key if using OpenAI\n",
        "api_key = None\n",
        "if backend == \"openai\":\n",
        "    try:\n",
        "        from google.colab import userdata\n",
        "        api_key = userdata.get('OPENAI_API_KEY')\n",
        "        if not api_key:\n",
        "            print(\"No OpenAI API key found! Add it to Colab Secrets.\")\n",
        "    except:\n",
        "        print(\"Could not access Colab Secrets.\")\n",
        "\n",
        "print(\"Upload PDF file...\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    print(f\"\\nProcessing: {filename}\")\n",
        "    result = translate_pdf(filename, target_language, backend, ollama_model, api_key)\n",
        "    output_file = f\"translated_{filename.replace('.pdf', '.txt')}\"\n",
        "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(result)\n",
        "    print(f\"\\nDownloading: {output_file}\")\n",
        "    files.download(output_file)"
      ],
      "metadata": {
        "id": "upload_translate"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
