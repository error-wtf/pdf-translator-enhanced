{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# ðŸ“„ PDF Translator - Google Colab\n",
        "\n",
        "**Translate scientific PDFs with local LLMs (Ollama) or OpenAI**\n",
        "\n",
        "> ðŸ”— **GitHub:** [error-wtf/pdf-translator-enhanced](https://github.com/error-wtf/pdf-translator-enhanced)  \n",
        "> Based on [thelanguagenerd/pdf-translator](https://github.com/thelanguagenerd/pdf-translator)\n",
        "\n",
        "Â© 2025 Sven Kalinowski with small help of Lino Casu  \n",
        "Licensed under the Anti-Capitalist Software License v1.4\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ†• Features\n",
        "\n",
        "- **ðŸ”¬ Formula Protection** - Mathematical formulas stay intact during translation\n",
        "- **ðŸŒ 20 Languages** - German, English, French, Spanish, Arabic, Hebrew, Ukrainian, Japanese, Chinese, and more\n",
        "- **ðŸ”’ 100% Local** - With Ollama, no data leaves Google's servers\n",
        "- **âš¡ GPU Accelerated** - Uses Colab's free T4 GPU\n",
        "\n",
        "---\n",
        "\n",
        "## Two Options:\n",
        "\n",
        "### Option A: Ollama (FREE, runs locally on Colab GPU)\n",
        "- No API key needed\n",
        "- Runs entirely on Google's servers\n",
        "- Your data stays in your Colab session\n",
        "- Requires GPU runtime (T4 is free)\n",
        "\n",
        "### Option B: OpenAI API (paid, better quality)\n",
        "- Requires OpenAI API key\n",
        "- Better translation quality (GPT-4)\n",
        "- Your data is sent to OpenAI servers\n",
        "\n",
        "---\n",
        "\n",
        "## GPU Runtime Setup\n",
        "\n",
        "1. Click **Runtime** â†’ **Change runtime type**\n",
        "2. Select **T4 GPU** (free) or **A100** (Colab Pro)\n",
        "3. Click **Save**\n",
        "\n",
        "| GPU | VRAM | Recommended Model | Speed |\n",
        "|-----|------|-------------------|-------|\n",
        "| T4 | 16 GB | `llama3.1:8b` | Medium |\n",
        "| L4 | 24 GB | `qwen2.5:14b` | Fast |\n",
        "| A100 | 40 GB | `mixtral:8x7b` | Very Fast |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "check_gpu"
      },
      "outputs": [],
      "source": [
        "#@title 1. Check GPU\n",
        "!nvidia-smi --query-gpu=name,memory.total --format=csv\n",
        "import torch\n",
        "print(f\"\\nCUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    vram_gb = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
        "    print(f\"VRAM: {vram_gb:.1f} GB\")\n",
        "    if vram_gb >= 16:\n",
        "        print(\"\\nRecommended: llama3.1:8b or qwen2.5:7b\")\n",
        "    elif vram_gb >= 24:\n",
        "        print(\"\\nRecommended: qwen2.5:14b or mistral-nemo:12b\")\n",
        "else:\n",
        "    print(\"\\nNo GPU! Please enable GPU runtime.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ollama_header"
      },
      "source": [
        "---\n",
        "# Option A: Ollama (FREE, Local)\n",
        "Run the following cells to use Ollama (no API key needed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_ollama"
      },
      "outputs": [],
      "source": [
        "#@title 2A. Install Ollama\n",
        "!curl -fsSL https://ollama.ai/install.sh | sh\n",
        "print(\"\\nOllama installed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "start_ollama"
      },
      "outputs": [],
      "source": [
        "#@title 3A. Start Ollama Server\n",
        "import subprocess\n",
        "import time\n",
        "import requests\n",
        "\n",
        "subprocess.Popen([\"ollama\", \"serve\"], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "print(\"Waiting for Ollama server...\")\n",
        "time.sleep(5)\n",
        "\n",
        "try:\n",
        "    r = requests.get(\"http://localhost:11434/api/tags\", timeout=5)\n",
        "    if r.status_code == 200:\n",
        "        print(\"Ollama server running!\")\n",
        "except:\n",
        "    print(\"Ollama server not reachable. Please run this cell again.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download_model"
      },
      "outputs": [],
      "source": [
        "#@title 6. PDF Translator Code\n",
        "import requests\n",
        "import re\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Tuple, Optional\n",
        "\n",
        "@dataclass\n",
        "class Block:\n",
        "    page: int\n",
        "    content: str\n",
        "    translated: str = \"\"\n",
        "\n",
        "OLLAMA_URL = \"http://localhost:11434\"\n",
        "\n",
        "# Language codes\n",
        "LANGUAGES = {\n",
        "    \"German\": \"de\", \"English\": \"en\", \"French\": \"fr\", \"Spanish\": \"es\",\n",
        "    \"Italian\": \"it\", \"Japanese\": \"ja\", \"Chinese\": \"zh\", \"Portuguese\": \"pt\",\n",
        "    \"Russian\": \"ru\", \"Korean\": \"ko\", \"Arabic\": \"ar\", \"Ukrainian\": \"uk\",\n",
        "    \"Hebrew\": \"he\", \"Dutch\": \"nl\", \"Polish\": \"pl\", \"Turkish\": \"tr\",\n",
        "    \"Swedish\": \"sv\", \"Czech\": \"cs\", \"Greek\": \"el\", \"Hindi\": \"hi\"\n",
        "}\n",
        "\n",
        "def protect_formulas(text: str) -> tuple:\n",
        "    \"\"\"Protect math formulas from translation.\"\"\"\n",
        "    protected = {}\n",
        "    counter = [0]\n",
        "    def protect(match):\n",
        "        key = f\"__FORMULA_{counter[0]}__\"\n",
        "        protected[key] = match.group(0)\n",
        "        counter[0] += 1\n",
        "        return key\n",
        "    patterns = [\n",
        "        r'\\$\\$[\\s\\S]*?\\$\\$',\n",
        "        r'\\$[^$\\n]+\\$',\n",
        "        r'\\\\begin\\{[^}]+\\}[\\s\\S]*?\\\\end\\{[^}]+\\}',\n",
        "        r'\\\\[a-zA-Z]+\\{[^}]*\\}',\n",
        "        r'\\\\[a-zA-Z]+',\n",
        "        r'\\d+\\.?\\d*\\s*[Ã—x]\\s*10\\^[âˆ’\\-]?\\d+',\n",
        "    ]\n",
        "    result = text\n",
        "    for pattern in patterns:\n",
        "        result = re.sub(pattern, protect, result)\n",
        "    return result, protected\n",
        "\n",
        "def restore_formulas(text: str, protected: dict) -> str:\n",
        "    \"\"\"Restore protected formulas after translation.\"\"\"\n",
        "    for key, value in protected.items():\n",
        "        text = text.replace(key, value)\n",
        "    return text\n",
        "\n",
        "def extract_pdf(pdf_path: str) -> Tuple[List[Block], str]:\n",
        "    import pdfplumber\n",
        "    from langdetect import detect\n",
        "    blocks = []\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for i, page in enumerate(pdf.pages):\n",
        "            text = page.extract_text(layout=True) or \"\"\n",
        "            for para in text.split(\"\\n\\n\"):\n",
        "                para = para.strip()\n",
        "                if para:\n",
        "                    blocks.append(Block(page=i+1, content=para))\n",
        "    sample = \" \".join(b.content for b in blocks[:3])\n",
        "    lang = detect(sample) if sample else \"en\"\n",
        "    return blocks, lang\n",
        "\n",
        "def translate_ollama(text: str, model: str, source: str, target: str) -> str:\n",
        "    if not text.strip():\n",
        "        return text\n",
        "    # Protect formulas\n",
        "    protected_text, formulas = protect_formulas(text)\n",
        "    system = f\"\"\"You are a professional scientific translator.\n",
        "Translate ALL text to {target} ONLY.\n",
        "Keep all __FORMULA_X__ placeholders unchanged.\n",
        "Output ONLY the translation.\"\"\"\n",
        "    user = f\"Translate from {source} to {target}:\\n\\n{protected_text}\"\n",
        "    try:\n",
        "        r = requests.post(f\"{OLLAMA_URL}/api/chat\", json={\n",
        "            \"model\": model,\n",
        "            \"messages\": [{\"role\": \"system\", \"content\": system}, {\"role\": \"user\", \"content\": user}],\n",
        "            \"stream\": False,\n",
        "            \"options\": {\"temperature\": 0.1, \"num_predict\": 8192}\n",
        "        }, timeout=300)\n",
        "        if r.status_code == 200:\n",
        "            result = r.json().get(\"message\", {}).get(\"content\", protected_text)\n",
        "            return restore_formulas(result, formulas)\n",
        "    except Exception as e:\n",
        "        print(f\"Ollama error: {e}\")\n",
        "    return text\n",
        "\n",
        "def translate_openai(text: str, api_key: str, source: str, target: str) -> str:\n",
        "    if not text.strip() or not api_key:\n",
        "        return text\n",
        "    # Protect formulas\n",
        "    protected_text, formulas = protect_formulas(text)\n",
        "    from openai import OpenAI\n",
        "    client = OpenAI(api_key=api_key)\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": f\"Translate to {target}. Keep __FORMULA_X__ placeholders unchanged. Output only translation.\"},\n",
        "                {\"role\": \"user\", \"content\": protected_text}\n",
        "            ],\n",
        "            temperature=0.1\n",
        "        )\n",
        "        result = response.choices[0].message.content\n",
        "        return restore_formulas(result, formulas)\n",
        "    except Exception as e:\n",
        "        print(f\"OpenAI error: {e}\")\n",
        "    return text\n",
        "\n",
        "def translate_pdf(pdf_path: str, target: str, backend: str = \"ollama\", model: str = \"llama3.1:8b\", api_key: str = None) -> str:\n",
        "    print(f\"ðŸ“„ Extracting: {pdf_path}\")\n",
        "    blocks, source = extract_pdf(pdf_path)\n",
        "    print(f\"ðŸ“Š {len(blocks)} blocks, detected language: {source}\")\n",
        "    print(f\"ðŸŒ Translating to {target} with {backend}...\")\n",
        "    for i, b in enumerate(blocks):\n",
        "        print(f\"  â³ Block {i+1}/{len(blocks)}\", end=\"\\r\")\n",
        "        if backend == \"openai\" and api_key:\n",
        "            b.translated = translate_openai(b.content, api_key, source, target)\n",
        "        else:\n",
        "            b.translated = translate_ollama(b.content, model, source, target)\n",
        "    print(f\"\\nâœ… Translation complete!\")\n",
        "    return \"\\n\\n\".join(b.translated for b in blocks)\n",
        "\n",
        "print(\"âœ… PDF Translator ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "openai_header"
      },
      "source": [
        "#@title 7. Upload and Translate PDF\n",
        "from google.colab import files\n",
        "\n",
        "#@markdown ### Settings\n",
        "target_language = \"German\" #@param [\"German\", \"English\", \"French\", \"Spanish\", \"Italian\", \"Japanese\", \"Chinese\", \"Portuguese\", \"Russian\", \"Korean\", \"Arabic\", \"Ukrainian\", \"Hebrew\", \"Dutch\", \"Polish\", \"Turkish\", \"Swedish\", \"Czech\", \"Greek\", \"Hindi\"]\n",
        "backend = \"ollama\" #@param [\"ollama\", \"openai\"]\n",
        "ollama_model = \"llama3.1:8b\" #@param [\"llama3.1:8b\", \"qwen2.5:7b\", \"qwen2.5:14b\", \"mistral:7b\", \"mistral-nemo:12b\"]\n",
        "\n",
        "# Get OpenAI key if using OpenAI\n",
        "api_key = None\n",
        "if backend == \"openai\":\n",
        "    try:\n",
        "        from google.colab import userdata\n",
        "        api_key = userdata.get('OPENAI_API_KEY')\n",
        "        if not api_key:\n",
        "            print(\"âš ï¸ No OpenAI API key found! Add it to Colab Secrets (key icon in sidebar).\")\n",
        "    except:\n",
        "        print(\"âš ï¸ Could not access Colab Secrets.\")\n",
        "\n",
        "print(\"ðŸ“¤ Upload your PDF file...\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    print(f\"\\nðŸ“„ Processing: {filename}\")\n",
        "    result = translate_pdf(filename, target_language, backend, ollama_model, api_key)\n",
        "    output_file = f\"translated_{filename.replace('.pdf', '.txt')}\"\n",
        "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(result)\n",
        "    print(f\"\\nâœ… Translation complete!\")\n",
        "    print(f\"ðŸ“¥ Downloading: {output_file}\")\n",
        "    files.download(output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup_openai"
      },
      "outputs": [],
      "source": [
        "#@title 2B. Setup OpenAI (Optional)\n",
        "!pip install -q openai\n",
        "\n",
        "# Try to get API key from Colab Secrets\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "    if OPENAI_API_KEY:\n",
        "        print(\"OpenAI API key loaded from Colab Secrets!\")\n",
        "        print(\"Your key is secure and only visible to you.\")\n",
        "    else:\n",
        "        print(\"No API key found. Add it to Colab Secrets (key icon in sidebar).\")\n",
        "except:\n",
        "    print(\"Colab Secrets not available. You can enter key manually below.\")\n",
        "    OPENAI_API_KEY = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_deps"
      },
      "outputs": [],
      "source": [
        "#@title 5. Install Dependencies\n",
        "!pip install -q PyPDF2 pdfplumber langdetect requests\n",
        "print(\"Dependencies installed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "translator_code"
      },
      "outputs": [],
      "source": [
        "#@title 6. PDF Translator Code\n",
        "import requests\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Tuple, Optional\n",
        "\n",
        "@dataclass\n",
        "class Block:\n",
        "    page: int\n",
        "    content: str\n",
        "    translated: str = \"\"\n",
        "\n",
        "OLLAMA_URL = \"http://localhost:11434\"\n",
        "\n",
        "def extract_pdf(pdf_path: str) -> Tuple[List[Block], str]:\n",
        "    import pdfplumber\n",
        "    from langdetect import detect\n",
        "    blocks = []\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for i, page in enumerate(pdf.pages):\n",
        "            text = page.extract_text(layout=True) or \"\"\n",
        "            for para in text.split(\"\\n\\n\"):\n",
        "                para = para.strip()\n",
        "                if para:\n",
        "                    blocks.append(Block(page=i+1, content=para))\n",
        "    sample = \" \".join(b.content for b in blocks[:3])\n",
        "    lang = detect(sample) if sample else \"en\"\n",
        "    return blocks, lang\n",
        "\n",
        "def translate_ollama(text: str, model: str, source: str, target: str) -> str:\n",
        "    if not text.strip():\n",
        "        return text\n",
        "    system = f\"\"\"You are a professional scientific translator.\n",
        "You MUST translate ALL text to {target} ONLY.\n",
        "NEVER use any other language than {target}.\n",
        "Keep all mathematical formulas unchanged.\n",
        "Output ONLY the translation.\"\"\"\n",
        "    user = f\"Translate from {source} to {target}. Keep formulas unchanged.\\n\\nText:\\n{text}\"\n",
        "    try:\n",
        "        r = requests.post(f\"{OLLAMA_URL}/api/chat\", json={\n",
        "            \"model\": model,\n",
        "            \"messages\": [{\"role\": \"system\", \"content\": system}, {\"role\": \"user\", \"content\": user}],\n",
        "            \"stream\": False,\n",
        "            \"options\": {\"temperature\": 0.1, \"num_predict\": 8192}\n",
        "        }, timeout=300)\n",
        "        if r.status_code == 200:\n",
        "            return r.json().get(\"message\", {}).get(\"content\", text)\n",
        "    except Exception as e:\n",
        "        print(f\"Ollama error: {e}\")\n",
        "    return text\n",
        "\n",
        "def translate_openai(text: str, api_key: str, source: str, target: str) -> str:\n",
        "    if not text.strip() or not api_key:\n",
        "        return text\n",
        "    from openai import OpenAI\n",
        "    client = OpenAI(api_key=api_key)\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": f\"Translate to {target}. Keep formulas unchanged. Output only translation.\"},\n",
        "                {\"role\": \"user\", \"content\": text}\n",
        "            ],\n",
        "            temperature=0.1\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        print(f\"OpenAI error: {e}\")\n",
        "    return text\n",
        "\n",
        "def translate_pdf(pdf_path: str, target: str, backend: str = \"ollama\", model: str = \"llama3.1:8b\", api_key: str = None) -> str:\n",
        "    print(f\"Extracting: {pdf_path}\")\n",
        "    blocks, source = extract_pdf(pdf_path)\n",
        "    print(f\"{len(blocks)} blocks, language: {source}\")\n",
        "    print(f\"Translating to {target} with {backend}...\")\n",
        "    for i, b in enumerate(blocks):\n",
        "        print(f\"  Block {i+1}/{len(blocks)}\", end=\"\\r\")\n",
        "        if backend == \"openai\" and api_key:\n",
        "            b.translated = translate_openai(b.content, api_key, source, target)\n",
        "        else:\n",
        "            b.translated = translate_ollama(b.content, model, source, target)\n",
        "    print(\"\\nDone!\")\n",
        "    return \"\\n\\n\".join(b.translated for b in blocks)\n",
        "\n",
        "print(\"PDF Translator ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upload_translate"
      },
      "outputs": [],
      "source": [
        "#@title 7. Upload and Translate PDF\n",
        "from google.colab import files\n",
        "\n",
        "#@markdown ### Settings\n",
        "target_language = \"German\" #@param [\"German\", \"English\", \"French\", \"Spanish\", \"Italian\", \"Japanese\", \"Chinese\"]\n",
        "backend = \"ollama\" #@param [\"ollama\", \"openai\"]\n",
        "ollama_model = \"llama3.1:8b\" #@param [\"llama3.1:8b\", \"qwen2.5:7b\", \"qwen2.5:14b\", \"mistral:7b\"]\n",
        "\n",
        "# Get OpenAI key if using OpenAI\n",
        "api_key = None\n",
        "if backend == \"openai\":\n",
        "    try:\n",
        "        from google.colab import userdata\n",
        "        api_key = userdata.get('OPENAI_API_KEY')\n",
        "        if not api_key:\n",
        "            print(\"No OpenAI API key found! Add it to Colab Secrets.\")\n",
        "    except:\n",
        "        print(\"Could not access Colab Secrets.\")\n",
        "\n",
        "print(\"Upload PDF file...\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    print(f\"\\nProcessing: {filename}\")\n",
        "    result = translate_pdf(filename, target_language, backend, ollama_model, api_key)\n",
        "    output_file = f\"translated_{filename.replace('.pdf', '.txt')}\"\n",
        "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(result)\n",
        "    print(f\"\\nDownloading: {output_file}\")\n",
        "    files.download(output_file)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
